{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link prediction problem\n",
    "\n",
    "- To build a model for predicting new protein-protein interaction\n",
    "\n",
    "- Reference : [Stanford SNAP tutorial](http://snap.stanford.edu/deepnetbio-ismb/ipynb/Graph+Convolutional+Prediction+of+Protein+Interactions+in+Yeast.html)\n",
    "\n",
    "- Tensflow 2.0 version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from numba import cuda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 20\n",
    "HIDDEN1 = 32\n",
    "HIDDEN2 = 16\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Various utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    g = nx.read_edgelist('yeast.edgelist')\n",
    "    adj = nx.adjacency_matrix(g)\n",
    "    return adj\n",
    "\n",
    "def sparse_dropout(x, keep_prob, noise_shape):\n",
    "    noise_shape = [noise_shape]\n",
    "    random_tensor = keep_prob\n",
    "    random_tensor += tf.random.uniform(noise_shape)\n",
    "    dropout_mask = tf.cast(tf.floor(random_tensor),dtype=tf.bool)\n",
    "    pre_out = tf.sparse.retain(x, dropout_mask)\n",
    "    return pre_out * (1./keep_prob)\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    if not sp.isspmatrix_coo(sparse_mx):\n",
    "        sparse_mx = sparse_mx.tocoo()\n",
    "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
    "    values = sparse_mx.data\n",
    "    shape = sparse_mx.shape\n",
    "    return coords, values, shape\n",
    "    \n",
    "def normalize_adj(adj):\n",
    "    adj = sp.coo_matrix(adj)\n",
    "    rowsum = np.array(adj.sum(1))\n",
    "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "\n",
    "def preprocess_adj(adj):\n",
    "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
    "    return sparse_to_tuple(adj_normalized)\n",
    "\n",
    "def dot(x, y, sparse=False):\n",
    "    if sparse:\n",
    "        res = tf.sparse.sparse_dense_matmul(x, y)\n",
    "    else:\n",
    "        res = tf.matmul(x, y)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_test_edges(adj):\n",
    "    # Function to build test set with 2% positive links\n",
    "    # Remove diagonal elements\n",
    "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "    adj.eliminate_zeros()\n",
    "\n",
    "    adj_triu = sp.triu(adj)\n",
    "    adj_tuple = sparse_to_tuple(adj_triu)\n",
    "    edges = adj_tuple[0]\n",
    "    edges_all = sparse_to_tuple(adj)[0]\n",
    "    print('number of triangle upper mtx:', len(edges))\n",
    "    print('number of edges_all:', len(edges_all))\n",
    "    num_test = int(np.floor(edges.shape[0] / 50.))\n",
    "    num_val = int(np.floor(edges.shape[0] / 50.))\n",
    "\n",
    "    all_edge_idx = list(range(edges.shape[0]))\n",
    "    np.random.shuffle(all_edge_idx)\n",
    "    val_edge_idx = all_edge_idx[:num_val]\n",
    "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
    "    test_edges = edges[test_edge_idx]\n",
    "    val_edges = edges[val_edge_idx]\n",
    "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
    "    print('num_train_edges:', len(train_edges))\n",
    "    print('num_val_edges:', len(val_edges))\n",
    "    print('num_test_edges:', len(test_edges))\n",
    "\n",
    "    def ismember(a, b):\n",
    "        rows_close = np.all((a - b[:, None]) == 0, axis=-1)\n",
    "        return np.any(rows_close)\n",
    "\n",
    "    test_edges_false = []\n",
    "    while len(test_edges_false) < len(test_edges):\n",
    "        n_rnd = len(test_edges) - len(test_edges_false)\n",
    "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
    "        idxs_i = rnd[:n_rnd]                                        \n",
    "        idxs_j = rnd[n_rnd:]\n",
    "        for i in range(n_rnd):\n",
    "            idx_i = idxs_i[i]\n",
    "            idx_j = idxs_j[i]\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], edges_all):\n",
    "                continue\n",
    "            if test_edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
    "                    continue\n",
    "            test_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    val_edges_false = []\n",
    "    while len(val_edges_false) < len(val_edges):\n",
    "        n_rnd = len(val_edges) - len(val_edges_false)\n",
    "        rnd = np.random.randint(0, adj.shape[0], size=2 * n_rnd)\n",
    "        idxs_i = rnd[:n_rnd]                                        \n",
    "        idxs_j = rnd[n_rnd:]\n",
    "        for i in range(n_rnd):\n",
    "            idx_i = idxs_i[i]\n",
    "            idx_j = idxs_j[i]\n",
    "            if idx_i == idx_j:\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], train_edges):\n",
    "                continue\n",
    "            if ismember([idx_i, idx_j], val_edges):\n",
    "                continue\n",
    "            if ismember([idx_j, idx_i], val_edges):\n",
    "                continue\n",
    "            if val_edges_false:\n",
    "                if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
    "                    continue\n",
    "                if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
    "                    continue\n",
    "            val_edges_false.append([idx_i, idx_j])\n",
    "\n",
    "    # Re-build adj matrix\n",
    "    data = np.ones(train_edges.shape[0])\n",
    "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
    "    adj_train = adj_train + adj_train.T\n",
    "\n",
    "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading\n",
    "\n",
    "### Adj matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6526\n",
      "1062675\n"
     ]
    }
   ],
   "source": [
    "adj = load_data()\n",
    "num_nodes = adj.shape[0]\n",
    "num_edges = adj.sum()\n",
    "\n",
    "print(num_nodes)\n",
    "print(num_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of triangle upper mtx: 530495\n",
      "number of edges_all: 1060990\n",
      "num_train_edges: 509277\n",
      "num_val_edges: 10609\n",
      "num_test_edges: 10609\n"
     ]
    }
   ],
   "source": [
    "# Store original adjacency matrix (without diagonal entries) for later\n",
    "adj_orig = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
    "adj_orig.eliminate_zeros()\n",
    "\n",
    "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
    "adj = adj_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_edges: 509277\n",
      "val_edges: 10609\n",
      "val_edges_false: 10609\n",
      "test_edges: 10609\n",
      "test_edges_false: 10609\n"
     ]
    }
   ],
   "source": [
    "print('train_edges:', len(train_edges))\n",
    "print('val_edges:', len(val_edges))\n",
    "print('val_edges_false:', len(val_edges_false))\n",
    "print('test_edges:', len(test_edges))\n",
    "print('test_edges_false:', len(test_edges_false))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0],\n",
       "        [   1,    0],\n",
       "        [   2,    0],\n",
       "        ...,\n",
       "        [4582, 6525],\n",
       "        [5312, 6525],\n",
       "        [6525, 6525]], dtype=int32),\n",
       " array([0.00104384, 0.00239487, 0.00150968, ..., 0.03594426, 0.04454354,\n",
       "        0.05555556]),\n",
       " (6526, 6526))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_norm = preprocess_adj(adj)\n",
    "adj_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix (Featureless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6526\n",
      "(6526,)\n"
     ]
    }
   ],
   "source": [
    "features = sparse_to_tuple(sp.identity(num_nodes))\n",
    "num_features = features[2][1]\n",
    "features_nonzero = features[1].shape\n",
    "\n",
    "print(num_features)\n",
    "print(features_nonzero)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(layers.Layer):\n",
    "    def __init__(self, input_dim, units, num_features_nonzero, issparse=False, dropout=0., act=tf.nn.relu, **kwargs):\n",
    "        super(GraphConvolution, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.units = units\n",
    "        self.num_features_nonzero = num_features_nonzero\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        self.issparse = issparse\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(shape=(self.input_dim, self.units),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True)\n",
    "        print('Shape of weights:', self.w.shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        x, adj = inputs\n",
    "        \n",
    "        if training is not False and self.issparse:\n",
    "            x = sparse_dropout(x, 1-self.dropout, self.num_features_nonzero)\n",
    "        elif training is not False:\n",
    "            x = tf.nn.dropout(x, self.dropout)\n",
    "            \n",
    "        x = dot(x, self.w, sparse=self.issparse)\n",
    "        x = dot(adj, x, sparse=True)  # adj는 tf.SparseTensor\n",
    "        outputs = self.act(x)\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "class InnerProductDecoder:\n",
    "    def __init__(self, input_dim, dropout=0., act=tf.nn.sigmoid):\n",
    "        self.issparse = False\n",
    "        self.dropout = dropout\n",
    "        self.act = act\n",
    "        \n",
    "    # 왜 x^Tx로 했을까?\n",
    "    def __call__(self, inputs, training=None):\n",
    "        x, _ = inputs\n",
    "        \n",
    "        x = tf.nn.dropout(x, self.dropout)\n",
    "        x_t = tf.transpose(x)\n",
    "        x = tf.matmul(x, x_t)\n",
    "        x = tf.reshape(x, [-1])\n",
    "        outputs = self.act(x)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(keras.Model):\n",
    "    \n",
    "    def __init__(self, input_dim, num_features_nonzero, **kwargs):\n",
    "        super(GCN, self).__init__(**kwargs)\n",
    "        self.input_dim = input_dim\n",
    "        self.num_features_nonzero = num_features_nonzero\n",
    "        self.layers_ = []\n",
    "        \n",
    "        print('input dim:', input_dim)\n",
    "        print('num_features_nonzero:', num_features_nonzero)\n",
    "        \n",
    "        self._build()\n",
    "        \n",
    "        for p in self.trainable_variables:\n",
    "            print(p.name, p.shape)\n",
    "            \n",
    "    def _build(self):\n",
    "        self.layers_.append(GraphConvolution(input_dim=self.input_dim,\n",
    "                                             units=HIDDEN1,\n",
    "                                             num_features_nonzero=self.num_features_nonzero,\n",
    "                                             issparse=True,\n",
    "                                             dropout=0.1))\n",
    "        \n",
    "        self.layers_.append(GraphConvolution(input_dim=HIDDEN1,\n",
    "                                             units=HIDDEN2,\n",
    "                                             num_features_nonzero=self.num_features_nonzero,\n",
    "                                             issparse=False,\n",
    "                                             dropout=0.1,\n",
    "                                             act=lambda x: x))\n",
    "        \n",
    "        self.layers_.append(InnerProductDecoder(input_dim=HIDDEN1,\n",
    "                                                dropout=0.1,\n",
    "                                                act=lambda x: x))\n",
    "    \n",
    "    def call(self, inputs, training=None):\n",
    "        x, labels, adj, num_nodes, num_edges = inputs\n",
    "        \n",
    "        outputs = [x]\n",
    "        for layer in self.layers_:\n",
    "            hidden = layer((outputs[-1], adj), training)\n",
    "            outputs.append(hidden)\n",
    "\n",
    "        output = outputs[-1]\n",
    "\n",
    "        # Weight decay loss\n",
    "        loss = tf.zeros([])\n",
    "        for var in self.layers_[0].trainable_variables:\n",
    "            loss += 5e-4 * tf.nn.l2_loss(var)\n",
    "\n",
    "        # Cost\n",
    "        pos_weight = tf.cast((num_nodes**2 - num_edges) / num_edges, dtype=tf.float32)\n",
    "        norm = tf.cast(num_nodes**2 / (num_nodes**2 - num_edges) * 2, dtype=tf.float32)\n",
    "        loss = norm * tf.reduce_mean(\n",
    "            tf.nn.weighted_cross_entropy_with_logits(logits=output, labels=labels, pos_weight=pos_weight))\n",
    "        \n",
    "        return loss, outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6526\n",
      "6526\n",
      "input dim: 6526\n",
      "num_features_nonzero: 6526\n"
     ]
    }
   ],
   "source": [
    "features = sparse_to_tuple(sp.identity(num_nodes))\n",
    "num_features = features[2][1]\n",
    "features_nonzero = features[1].shape[0]\n",
    "\n",
    "print(num_features)\n",
    "print(features_nonzero)\n",
    "\n",
    "model = GCN(features[2][1], features[1].shape[0])\n",
    "features = tf.SparseTensor(*features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "adj_label = sparse_to_tuple(adj_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tf.cast(tf.SparseTensor(*adj_norm), dtype=tf.float32))\n",
    "adj_norm = tf.SparseTensor(*adj_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_label = tf.SparseTensor(*adj_label)\n",
    "adj_label = tf.reshape(tf.sparse.to_dense(adj_label, validate_indices=False), [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam(lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roc_score(edges_pos, edges_neg):\n",
    "    _, outputs = model((features, adj_label, adj_norm, num_nodes, num_edges), training=False)\n",
    "    \n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    _, outputs = model((features, adj_label, adj_norm, num_nodes, num_edges), training=False)\n",
    "    emb = outputs[2].numpy()\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "        \n",
    "    preds = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        pos.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
    "        neg.append(adj_orig[e[0], e[1]])\n",
    "\n",
    "    preds_all = np.hstack([preds, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds))])\n",
    "    \n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    \n",
    "    return roc_score, ap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gcn_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Shape of weights: (6526, 32)\n",
      "Shape of weights: (32, 16)\n",
      "Epoch: 0001 train_loss= 2.72480 val_roc= 0.76218 val_ap= 0.68778 time= 1.11618\n",
      "Epoch: 0002 train_loss= 2.72479 val_roc= 0.77556 val_ap= 0.71130 time= 1.10709\n",
      "Epoch: 0003 train_loss= 2.72478 val_roc= 0.80676 val_ap= 0.76764 time= 1.12801\n",
      "Epoch: 0004 train_loss= 2.72466 val_roc= 0.85559 val_ap= 0.84723 time= 1.07825\n",
      "Epoch: 0005 train_loss= 2.72313 val_roc= 0.87665 val_ap= 0.86812 time= 1.09746\n",
      "Epoch: 0006 train_loss= 2.69961 val_roc= 0.87845 val_ap= 0.86901 time= 1.09530\n",
      "Epoch: 0007 train_loss= 2.56678 val_roc= 0.87837 val_ap= 0.86891 time= 1.10208\n",
      "Epoch: 0008 train_loss= 2.50911 val_roc= 0.87828 val_ap= 0.86890 time= 1.10518\n",
      "Epoch: 0009 train_loss= 2.46875 val_roc= 0.87815 val_ap= 0.86888 time= 1.14220\n",
      "Epoch: 0010 train_loss= 2.46392 val_roc= 0.87797 val_ap= 0.86879 time= 1.10489\n",
      "Epoch: 0011 train_loss= 2.47979 val_roc= 0.87783 val_ap= 0.86870 time= 1.09783\n",
      "Epoch: 0012 train_loss= 2.44912 val_roc= 0.87773 val_ap= 0.86865 time= 1.10556\n",
      "Epoch: 0013 train_loss= 2.43815 val_roc= 0.87756 val_ap= 0.86855 time= 1.11415\n",
      "Epoch: 0014 train_loss= 2.46046 val_roc= 0.87722 val_ap= 0.86833 time= 1.12201\n",
      "Epoch: 0015 train_loss= 2.42762 val_roc= 0.87673 val_ap= 0.86798 time= 1.10623\n",
      "Epoch: 0016 train_loss= 2.43123 val_roc= 0.87625 val_ap= 0.86763 time= 1.10731\n",
      "Epoch: 0017 train_loss= 2.44005 val_roc= 0.87597 val_ap= 0.86742 time= 1.09959\n",
      "Epoch: 0018 train_loss= 2.41855 val_roc= 0.87579 val_ap= 0.86729 time= 1.09364\n",
      "Epoch: 0019 train_loss= 2.41244 val_roc= 0.87552 val_ap= 0.86708 time= 1.10247\n",
      "Epoch: 0020 train_loss= 2.42245 val_roc= 0.87494 val_ap= 0.86662 time= 1.05857\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    curr_time = time.time()\n",
    "    with tf.GradientTape() as t:\n",
    "        loss, _ = model((features, adj_label, adj_norm, num_nodes, num_edges))\n",
    "    grads = t.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    roc_score, ap_score = get_roc_score(val_edges, val_edges_false)\n",
    "    \n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \n",
    "          \"train_loss=\", \"{:.5f}\".format(loss),\n",
    "          \"val_roc=\", \"{:.5f}\".format(roc_score),\n",
    "          \"val_ap=\", \"{:.5f}\".format(ap_score),\n",
    "          \"time=\", \"{:.5f}\".format(time.time() - curr_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8736581635464941, 0.8599647852129776)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_roc_score(test_edges, test_edges_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
